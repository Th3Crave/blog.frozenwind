<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="人生到处知何似，应似飞鸿踏雪泥。泥上偶然留指爪，鸿飞那复计东西。"><title>Elasticsearch | frozeNwInd</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement('script');
  hm.src = 'https://hm.baidu.com/hm.js?' + 'bbf19a98c9ae28f2e1e8cfcee1d9585e';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Elasticsearch</h1><a id="logo" href="/.">frozeNwInd</a><p class="description">吕乘风的博客</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-history"> 历史</i></a><a href="/message/"><i class="fa fa-comment"> 留言</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Elasticsearch</h1><div class="post-meta">2022-11-18<span> | </span><span class="category"><a href="/categories/technology/">technology</a></span></div><div class="post-content"><p>ElasticSearch是一款非常强大的、基于Lucene的开源搜索及分析引擎，它是一个实时的分布式<strong>全文</strong>搜索分析引擎。<br>ES中的数据都是来自于MySQL，用ES的目的不是来持久化数据的，而是因为它的数据检索、复杂数据分析的效率极高，用它来完成检索、分析的功能。</p>
<p>它被用作<strong>全文检索、结构化搜索、分析</strong>以及这三个功能的组合：</p>
<ul>
<li>Wikipedia 使用 Elasticsearch 提供带有高亮片段的全文搜索，还有 search-as-you-type 和 did-you-mean 的建议。</li>
<li>卫报 使用 Elasticsearch 将网络社交数据结合到访客日志中，为它的编辑们提供公众对于新文章的实时反馈。</li>
<li>Stack Overflow 将地理位置查询融入全文检索中去，并且使用 more-like-this 接口去查找相关的问题和回答。</li>
<li>GitHub 使用 Elasticsearch 对1300亿行代码进行查询。</li>
</ul>
<p>除了搜索，结合<strong>Kibana、Logstash、Beats</strong>开源产品，<strong>Elastic Stack（简称ELK）</strong>还被广泛运用在大数据近实时分析领域，包括：日志分析、指标监控、信息安全等。它可以帮助你探索海量结构化、非结构化数据，按需创建可视化报表，对监控数据设置报警阈值，通过使用机器学习，自动识别异常状况。</p>
<p>ElasticSearch是基于Restful WebApi，使用Java语言开发的搜索引擎库类，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。其客户端在Java、C#、PHP、Python等许多语言中都是可用的。</p>
<h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><h3 id="全文搜索"><a href="#全文搜索" class="headerlink" title="全文搜索"></a>全文搜索</h3><p>从全文数据中进行检索。</p>
<p>数据可分为：</p>
<ul>
<li>结构化数据<br>  指具有<strong>固定格式</strong>或<strong>有限长度</strong>的数据，如数据库、元数据等，可以用二维表结构来逻辑表达实现的数据</li>
<li>非结构化数据<br>  指不定长或无固定格式的数据，如邮件，word文档等。<br>  非结构化数据是数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维逻辑表来表现的数据，包括所有格式的办公文档、文本、图片、各类报表、图像和音频/视频信息等等。</li>
<li>半结构化数据<br>  如XML、HTML等，当根据需要可按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理。</li>
</ul>
<p>对于结构化数据，因为它们具有特定的结构，所以我们一般都是可以通过关系型数据库（MySQL、Oracle的）的二维表（Table）的方式存储和搜索，对表可以建立索引。</p>
<p><strong>对于非结构化数据，也即对全文数据的搜索主要有两种方法：</strong></p>
<ul>
<li><strong>顺序扫描</strong><br>  按照顺序扫描的方式查询特定的关键字。</li>
<li><strong>全文检索</strong><br>  将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。</li>
</ul>
<h3 id="Lucene"><a href="#Lucene" class="headerlink" title="Lucene"></a>Lucene</h3><h4 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h4><p>Elasticsearch是通过Lucene的倒排索引技术实现比关系型数据库更快的过滤。<br><strong>思考：其比关系型数据库的B+树索引快在哪里？为什么快？</strong></p>
<h3 id="ES基础"><a href="#ES基础" class="headerlink" title="ES基础"></a>ES基础</h3><ul>
<li><strong>cluster 集群</strong><br>  一个集群由一个唯一的名字标识，默认为“elasticsearch”。<br>  每个节点配置相同的 cluster.name 即可加入集群，集群名称可以在配置文件中指定。</li>
<li><strong>node 节点</strong></li>
<li><strong>Index 索引</strong><br>  一个索引是一个文档的集合。每个索引有唯一的名字，通过这个名字来操作它。一个集群中可以有任意多个索引。<br>  <img src="/2022/11/18/Elasticsearch/es-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5-index-shard-dev.png" alt="3个节点 2个index 各3个分片 零副本"><br>  <img src="/2022/11/18/Elasticsearch/es-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5-index-shard-prod.png" alt="3个节点 1个index 3个分片 2个副本"><ul>
<li><strong>shard 分片</strong><br>  ES支持PB级全文搜索，当某个索引上的数据量太大的时候，ES通过水平拆分的方式讲一个索引上的数据拆分出来分配到不同的数据块上，拆分出来的数据块称为一个分片。<br>  在创建索引的时候需要指定分片的数量，并且分片的数量一旦确定就不能修改，在一个多分片的索引中写入数据时，通过路由来确定具体写入哪一个分片中。<br>  <strong>ES中的每个shard分片本质上是Lucene中的一个索引文件</strong>，一个ES索引是分片的集合。<br>  当 Elasticsearch 在索引中搜索的时候，它发送查询到每一个属于索引的分片（Lucene 索引），然后合并每个分片的结果到一个全局的结果集。</li>
<li><strong>replica 副本</strong><br>  在一个网络 / 云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的， Elasticsearch 允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片(副本)。</li>
</ul>
</li>
<li><strong>type 类型</strong><br>  指在一个索引中，可以索引不同类型的文档，如用户数据、博客数据。<br>  从6.0版本起已废弃。7.0版本及之后，<strong>一个index中只有一个默认的type，即_doc</strong>。</li>
<li><strong>document 文档</strong><br>  被索引的一条数据，索引的基本信息单元，以JSON格式来表示。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;_index&quot;:	, 代表操作的哪个 index(库)</span><br><span class="line">    &quot;_type&quot;:	, 代表操作的哪个 type(表)</span><br><span class="line">    &quot;_id&quot;:    , 每条记录 都有一个 唯一标识，当无法判断是更新，还是insert操作的时候，看展示的_id,有没有变化，</span><br><span class="line">                有就是insert了一条新记录，没有就是 更新操作</span><br><span class="line">                还有可能是 没有执行更新/insert操作</span><br><span class="line">    &quot;_version&quot;:    , 代表这条记录的版本号（根据版本号，可以得知此记录是否被修改过，修改一次，版本号就会变化一次）</span><br><span class="line">    &quot;_source&quot;:    , json记录本体信息</span><br><span class="line">    &quot;_seq_no&quot;:    , 并发控制字段，每次更新+1，用来做乐观锁</span><br><span class="line">            应用：在 更新请求后加上 ?if_seq_no = 此时记录的 seq_no &amp; if_primary_term = 此时记录的 primary_term</span><br><span class="line">            这时如果，更新操作的时候，如果记录的 _seq_no != if_seq_no 的值，那么无法更新</span><br><span class="line">            这样当两个请求，同时操作这条记录的时候，一个请求已经更新了记录，那么 _seq_no + 1，下一个请求就无法 完成更新操作了</span><br><span class="line">    &quot;_primary&quot;:    , 集群，主分片重新分配，如重启，就会变化</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="/2022/11/18/Elasticsearch/es-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-rdbms%E5%AF%B9%E7%85%A7%E5%85%B3%E7%B3%BB-.png"></p>
<h2 id="Elastic-Stack生态"><a href="#Elastic-Stack生态" class="headerlink" title="Elastic Stack生态"></a>Elastic Stack生态</h2><p>Beats + Logstash + ElasticSearch + Kibana</p>
<p><img src="/2022/11/18/Elasticsearch/es-elk%E7%94%9F%E6%80%81.png"></p>
<p><strong>Beats</strong><br>Beats是一个面向轻量型采集器的平台，这些采集器可以从边缘机器向Logstash、ElasticSearch发送数据，它是由Go语言进行开发的，运行效率方面比较快。不同Beats的套件是针对不同的数据源。</p>
<p><strong>Logstash</strong><br>Logstash是动态数据收集管道，拥有可扩展的插件生态系统，支持从不同来源采集数据，转换数据，并将数据发送到不同的存储库中。其能够与ElasticSearch产生强大的协同作用，后被Elastic公司在2013年收购。</p>
<p><strong>ElasticSearch</strong><br>ElasticSearch对数据进行搜索、分析和存储，其是基于JSON的分布式搜索和分析引擎，专门为实现水平可扩展性、高可靠性和管理便捷性而设计的。<br>它的实现原理主要分为以下几个步骤：</p>
<ol>
<li>首先用户将数据提交到ElasticSearch数据库中；</li>
<li>再通过分词控制器将对应的语句分词；</li>
<li>将分词结果及其权重一并存入，以备用户在搜索数据时，根据权重将结果排名和打分，将返回结果呈现给用户。</li>
</ol>
<p><strong>Kibana</strong><br>Kibana实现数据可视化，其作用就是在ElasticSearch中进行民航。Kibana能够以图表的形式呈现数据，并且具有可扩展的用户界面，可以全方位的配置和管理ElasticSearch。</p>
<h3 id="从日志收集系统看ES-Stack的发展"><a href="#从日志收集系统看ES-Stack的发展" class="headerlink" title="从日志收集系统看ES Stack的发展"></a>从日志收集系统看ES Stack的发展</h3><p>一个典型的日志系统包括：<br>（1）收集：能够采集多种来源的日志数据<br>（2）传输：能够稳定的把日志数据解析过滤并传输到存储系统<br>（3）存储：存储日志数据<br>（4）分析：支持 UI 分析<br>（5）警告：能够提供错误报告，监控机制</p>
<p>beats+elasticsearch+kibana<br>beats+logstath+elasticsearch+kibana<br><img src="/2022/11/18/Elasticsearch/es-elk%E7%94%9F%E6%80%81-%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F2.png"><br>beats+MQ+logstash+elasticsearch+kibana<br><img src="/2022/11/18/Elasticsearch/es-elk%E7%94%9F%E6%80%81-%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F3.png"></p>
<h3 id="Elastic-Stack最佳实践"><a href="#Elastic-Stack最佳实践" class="headerlink" title="Elastic Stack最佳实践"></a>Elastic Stack最佳实践</h3><p><strong>日志收集系统</strong><br><strong>Metric收集和APM性能监控</strong><br><strong>多数据中心方案</strong></p>
<h2 id="ES原理-ElasticSearch-amp-Lucene"><a href="#ES原理-ElasticSearch-amp-Lucene" class="headerlink" title="ES原理 - ElasticSearch &amp; Lucene"></a>ES原理 - ElasticSearch &amp; Lucene</h2><p><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%9F%BA%E7%A1%80-%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84.png"></p>
<ul>
<li><strong>一个 ES Index</strong>在集群模式下，有多个 Node （节点）组成。每个节点就是 ES 的Instance (实例)。</li>
<li>每个节点上会有多个 shard（分片）， P0、P1是主分片, R0、R1是副本分片</li>
<li>每个分片上对应着就是一个 Lucene Index（底层索引文件）</li>
<li>Lucene Index 是一个统称 <ul>
<li>由多个 Segment （段文件，单个倒排索引文件称为Segment）组成。每个段文件存储着就是 Doc 文档。</li>
<li>commit point 记录了所有 segments 的信息。</li>
</ul>
</li>
</ul>
<h3 id="Lucene索引结构"><a href="#Lucene索引结构" class="headerlink" title="Lucene索引结构"></a>Lucene索引结构</h3><p>Lucene的索引结构中有哪些文件？<br><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%9F%BA%E7%A1%80-lucene%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84-%E6%96%87%E4%BB%B6.png"></p>
<p>文件的关系如下：<br><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%9F%BA%E7%A1%80-lucene%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84-%E6%96%87%E4%BB%B6%E5%85%B3%E7%B3%BB.jpeg"></p>
<h3 id="Lucene处理流程"><a href="#Lucene处理流程" class="headerlink" title="Lucene处理流程"></a>Lucene处理流程</h3><p><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%9F%BA%E7%A1%80-lucune%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.jpeg"></p>
<p><strong>创建索引的过程</strong></p>
<ul>
<li>准备待索引的原文档，数据来源可能是文件、数据库或网络</li>
<li>对文档的内容进行分词组件处理，形成一系列的Term</li>
<li>索引组件对文档和Term处理，形成字典和倒排表</li>
</ul>
<p><strong>搜索索引的过程</strong></p>
<ul>
<li>对查询语句进行分词处理，形成一系列Term</li>
<li>根据倒排索引表查找出包含Term的文档，并进行合并形成符合结果的文档集</li>
<li>比对查询语句与各个文档相关性得分，并按照得分高低返回</li>
</ul>
<h3 id="ElasticSearch分析器"><a href="#ElasticSearch分析器" class="headerlink" title="ElasticSearch分析器"></a>ElasticSearch分析器</h3><blockquote>
<p>ElasticSearch中最重要原理是文档的索引和文档的读取</p>
</blockquote>
<h2 id="ES原理-索引文档流程详解（写）"><a href="#ES原理-索引文档流程详解（写）" class="headerlink" title="ES原理 - 索引文档流程详解（写）"></a>ES原理 - 索引文档流程详解（写）</h2><h3 id="文档索引步骤顺序"><a href="#文档索引步骤顺序" class="headerlink" title="文档索引步骤顺序"></a>文档索引步骤顺序</h3><h4 id="单个文档"><a href="#单个文档" class="headerlink" title="单个文档"></a>单个文档</h4><p>某索引下新建单个文档所需要的步骤顺序：<br><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%86%99-%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3.png" alt="3个节点 1个索引 2个分片 2个副本"></p>
<ol>
<li>客户端向 Node 1 发送新建、更新或者删除请求。</li>
<li>节点使用文档的 _id 确定文档属于分片 0。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。</li>
<li>Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。</li>
</ol>
<h4 id="多个文档"><a href="#多个文档" class="headerlink" title="多个文档"></a>多个文档</h4><p>使用 bulk 修改多个文档步骤顺序：<br><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%86%99-%E5%A4%9A%E4%B8%AA%E6%96%87%E6%A1%A3.png" alt="3个节点 1个索引 2个分片 2个副本"></p>
<ol>
<li>客户端向 Node 1 发送 bulk 请求。</li>
<li>Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。</li>
<li>主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</li>
</ol>
<h3 id="文档索引过程详解"><a href="#文档索引过程详解" class="headerlink" title="文档索引过程详解"></a>文档索引过程详解</h3><h4 id="整体的索引过程"><a href="#整体的索引过程" class="headerlink" title="整体的索引过程"></a>整体的索引过程</h4><p><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%86%99-%E6%95%B4%E4%BD%93%E8%BF%87%E7%A8%8B.jpeg"></p>
<ol>
<li>协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。 <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shard = <span class="built_in">hash</span>(document_id) % (num_of_primary_shards)</span><br></pre></td></tr></table></figure></li>
<li>当分片所在的节点接收到来自协调节点的请求后，会将请求<strong>写入到Memory Buffer</strong>；然后定时（默认是每隔1秒）写入到Filesystem Cache，这个<strong>从Momery Buffer到Filesystem Cache的过程</strong>就叫做<strong>refresh</strong>；</li>
<li>当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当<strong>Filesystem cache中的数据写入到磁盘中</strong>时，才会清除掉，这个过程叫做<strong>flush</strong>。</li>
<li>在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。 flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时。</li>
</ol>
<h4 id="分步骤看数据持久化过程：write-gt-refresh-gt-flush-gt-merge"><a href="#分步骤看数据持久化过程：write-gt-refresh-gt-flush-gt-merge" class="headerlink" title="分步骤看数据持久化过程：write -&gt; refresh -&gt; flush -&gt; merge"></a>分步骤看数据持久化过程：write -&gt; refresh -&gt; flush -&gt; merge</h4><p><strong>write过程</strong><br><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%86%99-write.png"></p>
<p>一个新文档过来，会存储在 in-memory buffer 内存缓存区中，顺便会记录 Translog（Elasticsearch 增加了一个 translog ，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录）。<br>这时候数据还没到 segment ，是搜不到这个新文档的。数据只有被 refresh 后，才可以被搜索到。</p>
<p><strong>refresh过程</strong><br><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%86%99-refresh.png"></p>
<p>refresh 默认 1 秒钟，执行一次上图流程。ES 是支持修改这个值的，通过 index.refresh_interval 设置 refresh （冲刷）间隔时间。<br>refresh 流程大致如下：</p>
<ol>
<li>in-memory buffer 中的文档写入到新的 segment 中，但 segment 是存储在文件系统的缓存中。此时文档可以被搜索到。</li>
<li>最后清空 in-memory buffer。注意: Translog 没有被清空，为了将 segment 数据写到磁盘。</li>
</ol>
<p>文档经过 refresh 后， segment 暂时写到文件系统缓存，这样避免了性能 IO 操作，又可以使文档搜索到。<br>refresh 默认 1 秒执行一次，性能损耗太大。一般建议稍微延长这个 refresh 时间间隔，比如 5 s。因此，ES 其实就是准实时，达不到真正的实时。</p>
<p><strong>flush过程</strong><br>每隔一段时间（默认30分钟）或者 translog 变得越来越大（默认为512M），​索引被刷新（flush）：一个新的 translog 被创建，并且一个全量提交被执行。</p>
<p><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%86%99-flush.png"></p>
<p>文档从文件缓存写入磁盘的过程就是 flush。写入磁盘后，清空 translog。<br>具体过程如下：</p>
<ol>
<li>所有在内存缓冲区的文档都被写入一个新的段。</li>
<li>缓冲区被清空。</li>
<li>一个Commit Point被写入硬盘。</li>
<li>文件系统缓存通过 fsync 被刷新（flush）。</li>
<li>老的 translog 被删除。</li>
</ol>
<p><strong>merge过程</strong><br>由于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增。<br>而段数目太多会带来较大的麻烦。每一个段都会消耗文件句柄、内存和cpu运行周期。<br>更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。</p>
<p>Elasticsearch通过在后台进行Merge Segment来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。<br>当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p>
<p><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%86%99-merge-1.png"><br><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E5%86%99-merge-2.png"></p>
<p>一旦合并结束，老的段被删除。新的段被刷新（flush）到了磁盘，写入一个包含新段且排除旧的和较小的段的新提交点。</p>
<p>合并大的段需要消耗大量的I/O和CPU资源，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。</p>
<h3 id="深入ElasticSearch索引文档的实现机制"><a href="#深入ElasticSearch索引文档的实现机制" class="headerlink" title="深入ElasticSearch索引文档的实现机制"></a>深入ElasticSearch索引文档的实现机制</h3><h4 id="写操作的关键点"><a href="#写操作的关键点" class="headerlink" title="写操作的关键点"></a>写操作的关键点</h4><p>在考虑或分析一个分布式系统的写操作时，一般需要从下面几个方面考虑：</p>
<ul>
<li>可靠性：或者是持久性，数据写入系统成功后，数据不会被回滚或丢失。<br>  由于Lucene的设计中不考虑可靠性，在Elasticsearch中通过<strong>Replica</strong>和<strong>TransLog</strong>两套机制保证数据的可靠性。</li>
<li>一致性：数据写入成功后，再次查询时必须能保证读取到最新版本的数据，不能读取到旧数据。<br>  Lucene中的Flush锁只保证Update接口里面Delete和Add中间不会Flush，但是Add完成后仍然有可能立即发生Flush，导致Segment可读。这样就没法保证Primary和所有其他Replica可以同一时间Flush，就会出现查询不稳定的情况，这里只能实现最终一致性。</li>
<li>原子性：一个写入或者更新操作，要么完全成功，要么完全失败，不允许出现中间状态。<br>  Add和Delete都是直接调用Lucene的接口，是原子的。当部分更新时，使用Version和锁保证更新是原子的。</li>
<li>隔离性：多个写入操作相互不影响。<br>  仍然采用Version和局部锁来保证更新的是特定版本的数据。</li>
<li>实时性：写入后是否可以立即被查询到。<br>  使用定期Refresh Segment到内存，并且Reopen Segment方式保证搜索可以在较短时间（比如1秒）内被搜索到。通过将未刷新到磁盘数据记入TransLog，保证对未提交数据可以通过ID实时访问到。</li>
<li>性能：写入性能，吞吐量到底怎么样。</li>
</ul>
<h4 id="Lucene的写"><a href="#Lucene的写" class="headerlink" title="Lucene的写"></a>Lucene的写</h4><p>Elasticsearch内部使用了Lucene完成索引创建和搜索功能，Lucene中写操作主要是通过IndexWriter类实现，IndexWriter提供三个接口：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">addDocument</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">updateDocuments</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">deleteDocuments</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<p>通过这三个接口可以完成单个文档的写入、更新和删除功能，包括了分词、倒排创建、正排创建等等所有搜索相关的流程。<br>只要Doc通过IndesWriter写入后，后面就可以通过IndexSearcher搜索了，看起来功能已经完善了，但是仍然有一些问题没有解：</p>
<ul>
<li>上述操作是单机的，而不是我们需要的分布式。</li>
<li>文档写入Lucene后并不是立即可查询的，需要生成完整的Segment后才可被搜索，如何保证实时性？</li>
<li>Lucene生成的Segment是在内存中，如果机器宕机或掉电后，内存中的Segment会丢失，如何保证数据可靠性？</li>
<li>Lucene不支持部分文档更新，但是这又是一个强需求，如何支持部分更新？</li>
</ul>
<p>上述问题，在Lucene中是没有解决的，那么就需要Elasticsearch中解决上述问题。</p>
<h4 id="ElasticSearch的写"><a href="#ElasticSearch的写" class="headerlink" title="ElasticSearch的写"></a>ElasticSearch的写</h4><h4 id="ElasticSearch写入请求类型"><a href="#ElasticSearch写入请求类型" class="headerlink" title="ElasticSearch写入请求类型"></a>ElasticSearch写入请求类型</h4><h2 id="ES原理-读取文档流程详解（读）"><a href="#ES原理-读取文档流程详解（读）" class="headerlink" title="ES原理 - 读取文档流程详解（读）"></a>ES原理 - 读取文档流程详解（读）</h2><h3 id="文档查询步骤顺序"><a href="#文档查询步骤顺序" class="headerlink" title="文档查询步骤顺序"></a>文档查询步骤顺序</h3><h4 id="单个文档-1"><a href="#单个文档-1" class="headerlink" title="单个文档"></a>单个文档</h4><p><a href="es-%E5%8E%9F%E7%90%86-%E8%AF%BB-%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3.png"></a></p>
<ol>
<li>客户端向 Node 1 发送获取请求。</li>
<li>节点使用文档的 _id 来确定文档属于分片 0。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2。</li>
<li>Node 2 将文档返回给 Node 1，然后将文档返回给客户端。</li>
</ol>
<p>在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。</p>
<p>在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。</p>
<h4 id="多个文档-1"><a href="#多个文档-1" class="headerlink" title="多个文档"></a>多个文档</h4><p><a href="es-%E5%8E%9F%E7%90%86-%E8%AF%BB-%E5%A4%9A%E4%B8%AA%E6%96%87%E6%A1%A3.png"></a><br>以下是使用单个 mget 请求取回多个文档所需的步骤顺序：</p>
<ol>
<li>客户端向 Node 1 发送 mget 请求。</li>
<li>Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。</li>
</ol>
<h3 id="文档读取过程详解"><a href="#文档读取过程详解" class="headerlink" title="文档读取过程详解"></a>文档读取过程详解</h3><p>所有的搜索系统一般都是两阶段查询，第一阶段查询到匹配的DocID，第二阶段再查询DocID对应的完整文档，这种在Elasticsearch中称为query_then_fetch。<br><img src="/2022/11/18/Elasticsearch/es-%E5%8E%9F%E7%90%86-%E8%AF%BB-%E6%95%B4%E4%BD%93%E8%BF%87%E7%A8%8B.jpeg"></p>
<ol>
<li>在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在2. 搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。</li>
<li>每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</li>
<li>接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。</li>
</ol>
<h3 id="深入ElasticSearch读取文档的实现机制"><a href="#深入ElasticSearch读取文档的实现机制" class="headerlink" title="深入ElasticSearch读取文档的实现机制"></a>深入ElasticSearch读取文档的实现机制</h3><h4 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h4><ul>
<li>一致性指的是写入成功后，下次读操作一定要能读取到最新的数据。对于搜索，这个要求会低一些，可以有一些延迟。但是对于NoSQL数据库，则一般要求最好是强一致性的。</li>
<li>结果匹配上，NoSQL作为数据库，查询过程中只有符合不符合两种情况，而搜索里面还有是否相关，类似于NoSQL的结果只能是0或1，而搜索里面可能会有0.1，0.5，0.9等部分匹配或者更相关的情况。</li>
<li>结果召回上，搜索一般只需要召回最满足条件的Top N结果即可，而NoSQL一般都需要返回满足条件的所有结果。</li>
<li>搜索系统一般都是两阶段查询，第一个阶段查询到对应的Doc ID，也就是PK；第二阶段再通过Doc ID去查询完整文档，而NoSQL数据库一般是一阶段就返回结果。在Elasticsearch中两种都支持。</li>
</ul>
<p>目前NoSQL的查询，聚合、分析和统计等功能上都是要比搜索弱的。</p>
<h4 id="Lucene的读"><a href="#Lucene的读" class="headerlink" title="Lucene的读"></a>Lucene的读</h4><p>Elasticsearch使用了Lucene作为搜索引擎库，通过Lucene完成特定字段的搜索等功能，在Lucene中这个功能是通过IndexSearcher的下列接口实现的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// search接口实现搜索功能，返回最满足Query的N个结果</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> TopDocs <span class="title">search</span><span class="params">(Query query, <span class="keyword">int</span> n)</span></span>;</span><br><span class="line"><span class="comment">// doc接口通过doc id查询Doc内容</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Document <span class="title">doc</span><span class="params">(<span class="keyword">int</span> docID)</span></span>;</span><br><span class="line"><span class="comment">// count接口通过Query获取到命中数。</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">count</span><span class="params">(Query query)</span></span>;</span><br><span class="line">......(其他)</span><br></pre></td></tr></table></figure>
<p>这三个功能是搜索中的最基本的三个功能点，对于大部分Elasticsearch中的查询都是比较复杂的，直接用这个接口是无法满足需求的，比如分布式问题。<br>这些问题都留给了Elasticsearch解决。</p>
<h4 id="ElasticSearch的读"><a href="#ElasticSearch的读" class="headerlink" title="ElasticSearch的读"></a>ElasticSearch的读</h4></div><div id="donate"><link rel="stylesheet" type="text/css" href="/css/donate.css?v=1.0.0"><script type="text/javascript" src="/js/donate.js?v=1.0.0" successtext="复制成功!"></script><a class="pos-f tr3" id="github" href="https://github.com/Kaiyuan/donate-page" target="_blank" title="Github"></a><div id="DonateText">Donate</div><ul class="list pos-f" id="donateBox"><li id="AliPay" qr="/img/AliPayQR.png"></li><li id="WeChat" qr="/img/WeChatQR.png"></li></ul><div class="pos-f left-100" id="QRBox"><div id="MainBox"></div></div></div><div class="tags"><a href="/tags/Elasticsearch"><i class="fa fa-tag">Elasticsearch</i></a></div><div class="post-nav"><a class="pre" href="/2023/01/31/Java%E6%BA%90%E7%A0%81-ThreadLocal/">Java源码-ThreadLocal</a><a class="next" href="/2022/11/08/Java-JDK8%E3%80%81JDK11%E3%80%81JDK17/">JDK8、JDK11、JDK17</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
  clientID: '8359b7a19b78f2b9e112',
  clientSecret: '5ad69dc1633a1834322067d017b6313bd231457c',
  repo: 'gitalk',
  owner: 'Th3Crave',
  admin: ['Th3Crave'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar-toc"><div class="stoc-article" id="sidebar-stoc"><strong class="stoc-title"><i class="fa"> Contents </i></strong><div class="toc-nav" id="stoc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5"><span class="toc-text">基础概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E6%96%87%E6%90%9C%E7%B4%A2"><span class="toc-text">全文搜索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Lucene"><span class="toc-text">Lucene</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95"><span class="toc-text">倒排索引</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ES%E5%9F%BA%E7%A1%80"><span class="toc-text">ES基础</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Elastic-Stack%E7%94%9F%E6%80%81"><span class="toc-text">Elastic Stack生态</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F%E7%9C%8BES-Stack%E7%9A%84%E5%8F%91%E5%B1%95"><span class="toc-text">从日志收集系统看ES Stack的发展</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Elastic-Stack%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="toc-text">Elastic Stack最佳实践</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ES%E5%8E%9F%E7%90%86-ElasticSearch-amp-Lucene"><span class="toc-text">ES原理 - ElasticSearch &amp; Lucene</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Lucene%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84"><span class="toc-text">Lucene索引结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Lucene%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B"><span class="toc-text">Lucene处理流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ElasticSearch%E5%88%86%E6%9E%90%E5%99%A8"><span class="toc-text">ElasticSearch分析器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ES%E5%8E%9F%E7%90%86-%E7%B4%A2%E5%BC%95%E6%96%87%E6%A1%A3%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3%EF%BC%88%E5%86%99%EF%BC%89"><span class="toc-text">ES原理 - 索引文档流程详解（写）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E7%B4%A2%E5%BC%95%E6%AD%A5%E9%AA%A4%E9%A1%BA%E5%BA%8F"><span class="toc-text">文档索引步骤顺序</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3"><span class="toc-text">单个文档</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E4%B8%AA%E6%96%87%E6%A1%A3"><span class="toc-text">多个文档</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E7%B4%A2%E5%BC%95%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3"><span class="toc-text">文档索引过程详解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E7%9A%84%E7%B4%A2%E5%BC%95%E8%BF%87%E7%A8%8B"><span class="toc-text">整体的索引过程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%AD%A5%E9%AA%A4%E7%9C%8B%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%E8%BF%87%E7%A8%8B%EF%BC%9Awrite-gt-refresh-gt-flush-gt-merge"><span class="toc-text">分步骤看数据持久化过程：write -&gt; refresh -&gt; flush -&gt; merge</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%85%A5ElasticSearch%E7%B4%A2%E5%BC%95%E6%96%87%E6%A1%A3%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6"><span class="toc-text">深入ElasticSearch索引文档的实现机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%99%E6%93%8D%E4%BD%9C%E7%9A%84%E5%85%B3%E9%94%AE%E7%82%B9"><span class="toc-text">写操作的关键点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Lucene%E7%9A%84%E5%86%99"><span class="toc-text">Lucene的写</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ElasticSearch%E7%9A%84%E5%86%99"><span class="toc-text">ElasticSearch的写</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ElasticSearch%E5%86%99%E5%85%A5%E8%AF%B7%E6%B1%82%E7%B1%BB%E5%9E%8B"><span class="toc-text">ElasticSearch写入请求类型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ES%E5%8E%9F%E7%90%86-%E8%AF%BB%E5%8F%96%E6%96%87%E6%A1%A3%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3%EF%BC%88%E8%AF%BB%EF%BC%89"><span class="toc-text">ES原理 - 读取文档流程详解（读）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E6%9F%A5%E8%AF%A2%E6%AD%A5%E9%AA%A4%E9%A1%BA%E5%BA%8F"><span class="toc-text">文档查询步骤顺序</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3-1"><span class="toc-text">单个文档</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E4%B8%AA%E6%96%87%E6%A1%A3-1"><span class="toc-text">多个文档</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E8%AF%BB%E5%8F%96%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3"><span class="toc-text">文档读取过程详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%85%A5ElasticSearch%E8%AF%BB%E5%8F%96%E6%96%87%E6%A1%A3%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6"><span class="toc-text">深入ElasticSearch读取文档的实现机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%BB%E6%93%8D%E4%BD%9C"><span class="toc-text">读操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Lucene%E7%9A%84%E8%AF%BB"><span class="toc-text">Lucene的读</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ElasticSearch%E7%9A%84%E8%AF%BB"><span class="toc-text">ElasticSearch的读</span></a></li></ol></li></ol></li></ol></div><script type="text/javascript" src="/js/toc.js?v=1.0.0"></script></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2023 <a href="/." rel="nofollow">frozeNwInd.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
  search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>