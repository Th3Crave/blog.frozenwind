<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>消息队列——Kafka | frozeNwInd</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">消息队列——Kafka</h1><a id="logo" href="/.">frozeNwInd</a><p class="description">吕乘风的博客</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-history"> 历史</i></a><a href="/MoonAndStar/"><i class="fa fa-heart"> Moon&amp;Star</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">消息队列——Kafka</h1><div class="post-meta">2023-03-19<span> | </span><span class="category"><a href="/categories/technology/">technology</a></span></div><a class="disqus-comment-count" href="/2023/03/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E2%80%94%E2%80%94Kafka/#vcomment"><span class="valine-comment-count" data-xid="/2023/03/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E2%80%94%E2%80%94Kafka/"></span><span> 条评论</span></a><div class="post-content"><p>首次接触到Kafka的背景，<code>实时同步mysql数据到doris，Mysql binlog + kafka + flink + doris</code></p>
<p><img src="/2023/03/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E2%80%94%E2%80%94Kafka/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%91%E5%B1%95%E5%8F%B2.png" alt="消息队列发展史"><br><img src="/2023/03/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E2%80%94%E2%80%94Kafka/%E4%B8%BB%E6%B5%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.jpeg" alt="主流消息队列对比"></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Kafka 是一种分布式的，基于发布 / 订阅的消息系统。<br>主要设计目标如下：</p>
<ul>
<li>以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。</li>
<li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。</li>
<li>支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。</li>
<li>同时支持离线数据处理和实时数据处理。</li>
<li>Scale out：支持在线水平扩展。</li>
</ul>
<h3 id="创建背景"><a href="#创建背景" class="headerlink" title="创建背景"></a>创建背景</h3><p>Kafka 是一个消息系统，原本开发自 LinkedIn，用作 LinkedIn 的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。</p>
<h2 id="Kafka基础概念"><a href="#Kafka基础概念" class="headerlink" title="Kafka基础概念"></a>Kafka基础概念</h2><p><img src="/2023/03/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E2%80%94%E2%80%94Kafka/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.png"></p>
<h3 id="Kafka的特性"><a href="#Kafka的特性" class="headerlink" title="Kafka的特性"></a>Kafka的特性</h3><ul>
<li>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒。</li>
<li>可扩展性：kafka集群支持热扩展。</li>
<li>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失。</li>
<li>容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）。</li>
<li>高并发：支持数千个客户端同时读写。</li>
</ul>
<h4 id="Kafka为什么吞吐量大、速度快"><a href="#Kafka为什么吞吐量大、速度快" class="headerlink" title="Kafka为什么吞吐量大、速度快"></a>Kafka为什么吞吐量大、速度快</h4><ol>
<li><p><strong>Partition并行 分区分段+索引</strong><br> Kafka的message是按topic分类存储的，topic中的数据又是按照一个一个的partition即分区存储到不同broker节点。<br> 每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的。<br> 这也非常符合分布式系统分区分桶的设计思想。</p>
<p> 通过这种分区分段的设计，Kafka的message消息实际上是分布式存储在一个一个小的segment中的，每次文件操作也是直接操作的segment。<br> 为了进一步的查询优化，Kafka又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。<br> 这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。</p>
</li>
<li><p><strong>顺序读写磁盘</strong><br> Kafka的message是不断追加到本地磁盘文件末尾的，而不是随机的写入，这使得Kafka写入吞吐量得到了显著提升 。</p>
<blockquote>
<p>影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个 I/O 请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。<br>机械硬盘的<strong>连续读写</strong>性能很好，但<strong>随机读写</strong>性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是 IOPS 和吞吐量。<br>在许多的开源框架如 Kafka、HBase 中，都通过追加写的方式来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。</p>
</blockquote>
<p> Kafka的每一个Partition其实都是一个文件，收到消息后Kafka会把数据插入到文件末尾。</p>
<p> 这种方法有一个缺陷：<strong>没有办法删除数据</strong>。所以Kafka是不会删除数据的，它会把所有的数据都保留下来，每个消费者（Consumer）对每个Topic都有一个offset用来表示读取到了第几条数据。<br> 如果不删除硬盘肯定会被撑满，所以Kakfa提供了两种策略来删除数据。一是基于时间，二是基于partition文件大小。具体配置可以参看它的配置文档。</p>
</li>
<li><p><strong>Page Cache</strong></p>
<blockquote>
<p>操作系统层面引入 Cache 层的目的是为了提高 Linux 操作系统对磁盘访问的性能。Cache 层在内存中缓存了磁盘上的部分数据。当数据的请求到达时，如果在 Cache 中存在该数据且是最新的，则直接将数据传递给用户程序，免除了对底层磁盘的操作，提高了性能。<br>在 Linux 的实现中，文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache，每一个 Page Cache 包含若干 Buffer Cache。<br>Page Cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read/write 操作的时候。<br>Buffer Cache 则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。</p>
</blockquote>
<p>通过操作系统的Page Cache，Kafka的读写操作基本上是基于内存的，读写速度得到了极大的提升。</p>
</li>
<li><p><strong>零拷贝</strong><br> Kafka 中存在大量的<strong>网络数据持久化到磁盘（Producer 到 Broker）</strong>和<strong>磁盘文件通过网络发送（Broker 到 Consumer）</strong>的过程。这一过程的性能直接影响 Kafka 的整体吞吐量。</p>
<blockquote>
<p><img src="/2023/03/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E2%80%94%E2%80%94Kafka/%E9%9B%B6%E6%8B%B7%E8%B4%9D-%E5%85%A8%E9%83%A8%E6%8B%B7%E8%B4%9D%E8%BF%87%E7%A8%8B.jpg"><br>在实际应用中，把磁盘中的某个文件内容发送到远程服务器上，必须要经过几个拷贝的过程：</p>
<ol>
<li>从磁盘中读取目标文件内容拷贝到内核缓冲区；</li>
<li>CPU控制器再把内核缓冲区的数据赋值到用户空间的缓冲区中；</li>
<li>接着在应用程序中，调用write()方法，把用户空间缓冲区中的数据拷贝到内核下的Socket Buffer中；</li>
<li>最后，把在内核模式下的SocketBuffer中的数据赋值到网卡缓冲区（NIC Buffer），网卡缓冲区再把数据传输到目标服务器上。</li>
</ol>
</blockquote>
<blockquote>
<p>在这个过程中我们可以发现，数据从磁盘到最终发送出去，要经历4次拷贝，而在这四次拷贝过程中，有两次拷贝是浪费的，分别是：</p>
<ol>
<li>从内核空间赋值到用户空间</li>
<li>从用户空间再次复制到内核空间</li>
</ol>
</blockquote>
<blockquote>
<p>零拷贝，就是把这两次多于的拷贝省略掉，应用程序可以直接把磁盘中的数据从内核中直接传输给Socket，而不需要再经过应用程序所在的用户空间。<br><img src="/2023/03/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E2%80%94%E2%80%94Kafka/%E9%9B%B6%E6%8B%B7%E8%B4%9D-%E9%9B%B6%E6%8B%B7%E8%B4%9D%E8%BF%87%E7%A8%8B.jpg"><br>零拷贝通过DMA（Direct Memory Access，直接存储器访问）技术把文件内容复制到内核空间中的Read Buffer，接着把包含数据位置和长度信息的文件描述符加载到Socket Buffer中，DMA引擎直接可以把数据从内核空间中传递给网卡设备。<br>在这个流程中，数据只经历了两次拷贝就发送到了网卡中，并且减少了2次cpu的上下文切换，对于效率有非常大的提高。<br>所以，所谓零拷贝，并不是完全没有数据赋值，只是相对于用户空间来说，不再需要进行数据拷贝。对于前面说的整个流程来说，零拷贝只是避免了在内核空间和用户空间之间的拷贝。</p>
</blockquote>
<ul>
<li><code>Producer 生产的数据持久化到 broker</code>，采用 mmap 文件映射，实现磁盘的快速写入。<br>   mmap 文件映射（Memory Mapped Files）：将磁盘文件映射到内存, 用户通过修改内存就能修改磁盘文件</li>
<li><code>Customer 从 broker 读取数据</code>，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，转到 NIO buffer 进行网络发送，减少 CPU 消耗。</li>
</ul>
</li>
<li><p><strong>批处理 批量读写</strong><br> Kafka数据读写也是批量的而不是单条的。</p>
<p> 除了利用底层的技术外，Kafka还在应用程序层面提供了一些手段来提升性能。最明显的就是使用批次。<br> 在向Kafka写入数据时，可以启用批次写入，这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。<br> 假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。</p>
</li>
<li><p><strong>数据压缩</strong><br> 在很多情况下，系统的瓶颈不是 CPU 或磁盘，而是网络 IO。<br> Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。</p>
</li>
</ol>
<h3 id="概念1-生产者与消费者"><a href="#概念1-生产者与消费者" class="headerlink" title="概念1 生产者与消费者"></a>概念1 生产者与消费者</h3><p>对于 Kafka 来说，客户端有两种基本类型：生产者（Producer）和消费者（Consumer）。<br>除此之外，还有用来做数据集成的 Kafka Connect API 和流式处理的 Kafka Streams 等高阶客户端，但这些高阶客户端底层仍然是生产者和消费者API，它们只不过是在上层做了封装。</p>
<ul>
<li><strong>Producer</strong><br>  消息生产者，就是向 kafka broker 发消息的客户端。</li>
<li><strong>Consumer</strong><br>  消息消费者，向 kafka broker 取消息的客户端。</li>
<li><strong>Consumer Group</strong><br>  消费者组，由多个 consumer 组成，消费者组是逻辑上的一个订阅者。<br>  同一个消费者组中，一个消费者只能消费一个分区里面的数据。<ul>
<li><strong>重平衡：Rebalance</strong><br>  消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。<br>  Rebalance 是 Kafka 消费者端实现高可用的重要手段。</li>
</ul>
</li>
</ul>
<h3 id="概念2-主题-Topic-与分区-Partition"><a href="#概念2-主题-Topic-与分区-Partition" class="headerlink" title="概念2 主题(Topic)与分区(Partition)"></a>概念2 主题(Topic)与分区(Partition)</h3><ul>
<li><p><strong>Topic</strong><br>  Topic是一个逻辑上的消息队列，同一类型的消息可以放到一个Topic（消息队列）中。<br>  主要作用是用来屏蔽底层分区和副本的复杂逻辑。</p>
</li>
<li><p><strong>Partition</strong><br>  Partition（分区），是Kafka下数据存储的基本单元，这个是物理上的概念。</p>
<p>  一个 topic 可以分为多个 partition，每个 partition 都是一个有序的队列。<br>  主题可以被分为若干个分区（partition），同一个主题中的分区可以不在一个机器上，有可能会部署在多个机器上，由此来实现 kafka 的伸缩性，单一主题中的分区有序，但是无法保证主题中所有的分区有序。</p>
<p>  同一个分区（partition）可以被不同的消费者组同时消费；但是在同一个消费者组内，一个分区只能被一个消费者消费。</p>
</li>
</ul>
<h4 id="当broker里面的topic数量过多时，kafka的性能不如rocketMq？"><a href="#当broker里面的topic数量过多时，kafka的性能不如rocketMq？" class="headerlink" title="当broker里面的topic数量过多时，kafka的性能不如rocketMq？"></a>当broker里面的topic数量过多时，kafka的性能不如rocketMq？</h4><blockquote>
<p>Kafka与RocketMQ在topic处理上的不同</p>
<ol>
<li>kafka中partition增多会存在随机写的可能性，partition之间刷盘的冲撞率会高，但是RocketMQ是把消息都写到一个CommitLog文件中，所以相当于一个文件的顺序写。</li>
<li>RockertMQ的consumerQueue消息格式大小固定（20字节），写入pagecache之后被触发刷盘频率相对较低。</li>
</ol>
</blockquote>
<ul>
<li><p><strong>Replica</strong><br>  Replica（副本），就是Partition的一个备份，副本的数量是可以配置的。</p>
<p>  Kafka 定义了两类副本：领导者副本（Leader Replica） 和 追随者副本（Follower Replica），前者对外提供服务，后者只是被动跟随。</p>
<p>  一个分区（Partition）只能有一个leader，但是可以设置多个副本（follower），同一分区的副本不能在同一台机器上。也就是说如果有 3 台 Broker，那么一个分区就最多会有 2 个副本。</p>
<p>  <strong>leader partition</strong>：<br>  1、写数据、读数据操作都是从leader partition去操作的。<br>  2、会维护一个ISR（in-sync-replica）列表，但是会根据一定的规则删除ISR列表里面的值。生产者发送来一个消息，消息首先要写入到leader partition中，写完了以后，还要把消息写入到ISR列表里面的其它分区，写完后才算这个消息提交。</p>
<p>  <strong>follower partition</strong>：从leader partition同步数据。</p>
<p>  当 leader 发生故障时，某个 follower 会成为新的 leader，以此来保证kafka的可用性。</p>
<p>  自 Kafka 2.4 之后，Kafka 提供了有限度的读写分离，也就是说，Follower 副本能够对外提供读服务。</p>
</li>
</ul>
<h4 id="Leader-和-Follower-的消息序列在实际场景中不一致"><a href="#Leader-和-Follower-的消息序列在实际场景中不一致" class="headerlink" title="Leader 和 Follower 的消息序列在实际场景中不一致"></a>Leader 和 Follower 的消息序列在实际场景中不一致</h4><p>很多原因都可能造成 Leader 和 Follower 保存的消息序列不一致，比如程序 Bug、网络问题等。这是很严重的错误，必须要完全规避。<br>之前确保一致性的主要手段是高水位机制 High watermark，但高水位值无法保证 Leader 连续变更场景下的数据一致性，因此，社区引入了 Leader Epoch 机制，来修复高水位值的弊端。</p>
<h3 id="概念3-Broker和集群-Cluster"><a href="#概念3-Broker和集群-Cluster" class="headerlink" title="概念3 Broker和集群(Cluster)"></a>概念3 Broker和集群(Cluster)</h3><p>一台 kafka 服务器就是一个 broker。<br>一个kafka集群由多个 broker 组成，然后通过Zookeeper来进行集群的管理。</p>
<ul>
<li><p><strong>Zookeeper</strong><br>  2.8.0版本之前，Kafka 将 Broker、Topic 和 Partition 的元数据信息存储在 Zookeeper 上。</p>
<p>  通过在 Zookeeper 上建立相应的数据节点，并监听节点的变化，Kafka 使用 Zookeeper 完成以下功能：</p>
<ul>
<li>Kafka Controller 的 Leader 选举</li>
<li>Kafka 集群成员管理</li>
<li>Topic 配置管理</li>
<li>分区副本管理</li>
</ul>
</li>
<li><p><strong>Controller</strong><br>  Controller 是从 Broker 中选举出来的，负责分区 Leader 和 Follower 的管理。</p>
</li>
</ul>
<h3 id="核心API"><a href="#核心API" class="headerlink" title="核心API"></a>核心API</h3><p><img src="/2023/03/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E2%80%94%E2%80%94Kafka/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5-%E6%A0%B8%E5%BF%83api.jpeg"></p>
<ul>
<li>Producer API<br>允许应用程序向一个或多个 topics 上发送消息记录。</li>
<li>Consumer API<br>允许应用程序订阅一个或多个 topics 并对发布给他们的流式数据进行处理。</li>
<li>Streams API<br>它允许应用程序作为流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。</li>
<li>Connector API<br>它允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。<br>比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6963101806402469902#heading-7">https://juejin.cn/post/6963101806402469902#heading-7</a></p>
<h2 id="Kafka-Producer"><a href="#Kafka-Producer" class="headerlink" title="Kafka Producer"></a>Kafka Producer</h2><h2 id="Kafka-Consumer"><a href="#Kafka-Consumer" class="headerlink" title="Kafka Consumer"></a>Kafka Consumer</h2><h2 id="Kafka-Broker"><a href="#Kafka-Broker" class="headerlink" title="Kafka Broker"></a>Kafka Broker</h2><h2 id="版本演进"><a href="#版本演进" class="headerlink" title="版本演进"></a>版本演进</h2><h3 id="0-7-x"><a href="#0-7-x" class="headerlink" title="0.7.x"></a>0.7.x</h3><p>只提供最基础的消息队列功能。</p>
<h3 id="0-8-x"><a href="#0-8-x" class="headerlink" title="0.8.x"></a>0.8.x</h3><ul>
<li>Kafka 0.8.0增加了副本机制<br>  至此 Kafka 成为了一个真正意义上完备的分布式高可用消息队列解决方案。</li>
<li>Kafka 0.8.2.0引入了新版本Producer API</li>
</ul>
<h3 id="0-9-x"><a href="#0-9-x" class="headerlink" title="0.9.x"></a>0.9.x</h3><p>Kafka 0.9 是一个重大的版本迭代，增加了非常多的新特性，主要体现在三个方面：</p>
<ul>
<li>安全方面<br>  在0.9.0之前，Kafka安全方面的考虑几乎为0。<br>  Kafka 0.9.0 在安全认证、授权管理、数据加密等方面都得到了支持，包括支持Kerberos等。</li>
<li>新版本Consumer APi<br>  Kafka 0.9.0 重写并提供了新版消费端API，使用方式也是从连接Zookeeper切到了连接Broker，但是此时新版Consumer API也不太稳定、存在不少Bug，生产使用可能会比较痛苦；<br>  而0.9.0版本的Producer API已经比较稳定了，生产使用问题不大。</li>
<li>Kafka Connect<br>  Kafka 0.9.0 引入了新的组件 Kafka Connect ，用于实现Kafka与其他外部系统之间的数据抽取。</li>
</ul>
<h3 id="0-10-x"><a href="#0-10-x" class="headerlink" title="0.10.x"></a>0.10.x</h3><p>Kafka 0.10 是一个重要的大版本，因为Kafka 0.10.0.0 引入了 Kafka Streams，使得Kafka不再仅是一个消息引擎，而是往一个分布式流处理平台方向发展。<br>0.10 大版本包含两个小版本：0.10.1 和 0.10.2，它们的主要功能变更都是在 Kafka Streams 组件上。</p>
<p>值得一提的是，自 0.10.2.2 版本起，新版本 Consumer API 已经比较稳定了，而且 Producer API 的性能也得到了提升，因此对于使用 0.10.x 大版本的用户，建议使用或升级到 Kafka 0.10.2.2 版本。</p>
<h3 id="0-11-x"><a href="#0-11-x" class="headerlink" title="0.11.x"></a>0.11.x</h3><p>Kafka 0.11 是一个里程碑式的大版本，主要有两个大的变更。</p>
<ol>
<li>Kafka从这个版本开始支持Exactly-Once 语义即精准一次语义<br> 主要是实现了Producer端的消息幂等性，以及事务特性，这对于Kafka流式处理具有非常大的意义。</li>
<li>Kafka消息格式的重构<br> Kafka 0.11主要为了实现Producer幂等性与事务特性，重构了投递消息的数据结构。<br> 这一点非常值得关注，因为Kafka 0.11之后的消息格式发生了变化，所以我们要特别注意Kafka不同版本间消息格式不兼容的问题。</li>
</ol>
<h3 id="1-x"><a href="#1-x" class="headerlink" title="1.x"></a>1.x</h3><p>Kafka 1.x 更多的是Kafka Streams方面的改进，以及Kafka Connect的改进与功能完善等。<br>但仍有两个重要特性：</p>
<ol>
<li>Kafka 1.0.0实现了磁盘的故障转移<br> 当Broker的某一块磁盘损坏时数据会自动转移到其他正常的磁盘上，Broker还会正常工作，这在之前版本中则会直接导致Broker宕机，因此Kafka的可用性与可靠性得到了提升</li>
<li>Kafka 1.1.0开始支持副本跨路径迁移<br> 分区副本可以在同一Broker不同磁盘目录间进行移动，这对于磁盘的负载均衡非常有意义。</li>
</ol>
<h3 id="2-x"><a href="#2-x" class="headerlink" title="2.x"></a>2.x</h3><p>Kafka 2.x 更多的也是Kafka Streams、Connect方面的性能提升与功能完善，以及安全方面的增强等。</p>
<ul>
<li>Kafka 2.1.0开始支持ZStandard的压缩方式，提升了消息的压缩比，显著减少了磁盘空间与网络io消耗。</li>
<li>Kafka 2.8.0 用自管理的Quorum代替ZooKeeper管理元数据</li>
</ul>
<h4 id="为什么Kafka在2-8版本中会“抛弃”Zookeeper"><a href="#为什么Kafka在2-8版本中会“抛弃”Zookeeper" class="headerlink" title="为什么Kafka在2.8版本中会“抛弃”Zookeeper"></a>为什么Kafka在2.8版本中会“抛弃”Zookeeper</h4><h3 id="3-x"><a href="#3-x" class="headerlink" title="3.x"></a>3.x</h3></div><div id="donate"><link rel="stylesheet" type="text/css" href="/css/donate.css?v=1.0.0"><script type="text/javascript" src="/js/donate.js?v=1.0.0" successtext="复制成功!"></script><a class="pos-f tr3" id="github" href="https://github.com/Kaiyuan/donate-page" target="_blank" title="Github"></a><div id="DonateText">Donate</div><ul class="list pos-f" id="donateBox"><li id="AliPay" qr="/img/AliPayQR.png"></li><li id="WeChat" qr="/img/WeChatQR.png"></li></ul><div class="pos-f left-100" id="QRBox"><div id="MainBox"></div></div></div><div class="tags"><a href="/tags/消息队列"><i class="fa fa-tag">消息队列</i></a></div><div class="post-nav"><a class="next" href="/2023/03/18/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E2%80%94%E2%80%94%E5%8C%BA%E5%88%AB-%E5%AF%B9%E6%AF%94-%E9%80%89%E5%9E%8B/">消息队列—区别/对比/选型</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == 'true' ? true : false;
var verify = 'false' == 'true' ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'NPvQJfh7XNHqMqbmVYOg5VE5-9Nh9j0Va',
  appKey:'hgOdKtBYlsJzigDKoXqevrSI',
  placeholder:'我想听你说一句… （留言请填写您的昵称和邮箱，方便回复以邮件形式通知您）',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar-toc"><div class="stoc-article" id="sidebar-stoc"><strong class="stoc-title"><i class="fa"> Contents </i></strong><div class="toc-nav" id="stoc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-text">简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%83%8C%E6%99%AF"><span class="toc-text">创建背景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5"><span class="toc-text">Kafka基础概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%9A%84%E7%89%B9%E6%80%A7"><span class="toc-text">Kafka的特性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Kafka%E4%B8%BA%E4%BB%80%E4%B9%88%E5%90%9E%E5%90%90%E9%87%8F%E5%A4%A7%E3%80%81%E9%80%9F%E5%BA%A6%E5%BF%AB"><span class="toc-text">Kafka为什么吞吐量大、速度快</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E5%BF%B51-%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-text">概念1 生产者与消费者</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E5%BF%B52-%E4%B8%BB%E9%A2%98-Topic-%E4%B8%8E%E5%88%86%E5%8C%BA-Partition"><span class="toc-text">概念2 主题(Topic)与分区(Partition)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BD%93broker%E9%87%8C%E9%9D%A2%E7%9A%84topic%E6%95%B0%E9%87%8F%E8%BF%87%E5%A4%9A%E6%97%B6%EF%BC%8Ckafka%E7%9A%84%E6%80%A7%E8%83%BD%E4%B8%8D%E5%A6%82rocketMq%EF%BC%9F"><span class="toc-text">当broker里面的topic数量过多时，kafka的性能不如rocketMq？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Leader-%E5%92%8C-Follower-%E7%9A%84%E6%B6%88%E6%81%AF%E5%BA%8F%E5%88%97%E5%9C%A8%E5%AE%9E%E9%99%85%E5%9C%BA%E6%99%AF%E4%B8%AD%E4%B8%8D%E4%B8%80%E8%87%B4"><span class="toc-text">Leader 和 Follower 的消息序列在实际场景中不一致</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E5%BF%B53-Broker%E5%92%8C%E9%9B%86%E7%BE%A4-Cluster"><span class="toc-text">概念3 Broker和集群(Cluster)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83API"><span class="toc-text">核心API</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Producer"><span class="toc-text">Kafka Producer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Consumer"><span class="toc-text">Kafka Consumer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Broker"><span class="toc-text">Kafka Broker</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B"><span class="toc-text">版本演进</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#0-7-x"><span class="toc-text">0.7.x</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0-8-x"><span class="toc-text">0.8.x</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0-9-x"><span class="toc-text">0.9.x</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0-10-x"><span class="toc-text">0.10.x</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#0-11-x"><span class="toc-text">0.11.x</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-x"><span class="toc-text">1.x</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-x"><span class="toc-text">2.x</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88Kafka%E5%9C%A82-8%E7%89%88%E6%9C%AC%E4%B8%AD%E4%BC%9A%E2%80%9C%E6%8A%9B%E5%BC%83%E2%80%9DZookeeper"><span class="toc-text">为什么Kafka在2.8版本中会“抛弃”Zookeeper</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-x"><span class="toc-text">3.x</span></a></li></ol></li></ol></div><script type="text/javascript" src="/js/toc.js?v=1.0.0"></script></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2023 <a href="/." rel="nofollow">frozeNwInd.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
  search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>